import logging
import asyncio
from . import logger_config

from dotenv import load_dotenv

from livekit.agents import (
    Agent,
    AgentServer,
    AgentSession,
    JobContext,
    JobProcess,
    MetricsCollectedEvent,
    RunContext,
    cli,
    metrics,
    room_io,
    llm,
)
# Integration imports
from app.agent.sales_llm import SalesLLM
from app.agent.prompts import DETERMINISTIC_SYSTEM_PROMPT

logger = logging.getLogger("basic-agent")

load_dotenv()


class MyAgent(Agent):
    def __init__(self) -> None:
        super().__init__(
            instructions=DETERMINISTIC_SYSTEM_PROMPT,
        )

    async def on_enter(self):
        # Initial greeting generated by SalesAgent
        self.session.generate_reply(allow_interruptions=False)


server = AgentServer()


def prewarm(proc: JobProcess):
    from livekit.plugins import silero
    proc.userdata["vad"] = silero.VAD.load()


server.setup_fnc = prewarm


@server.rtc_session()
async def entrypoint(ctx: JobContext):
    ctx.log_context_fields = {
        "room": ctx.room.name,
    }

    # Session ID corresponds to room name for memory persistence
    session_id = ctx.room.name
    
    from livekit.plugins.turn_detector.multilingual import MultilingualModel
    
    session = AgentSession(
        stt="deepgram/nova-3",
        # worker.py acts only as an orchestrator. SalesAgent acts as the brain.
        llm=SalesLLM(session_id, ctx.room),
        tts="cartesia/sonic-2:9626c31c-bec5-4cca-baa8-f8ba9e84c8bc",
        turn_detection=MultilingualModel(),
        vad=ctx.proc.userdata["vad"],
        min_endpointing_delay=0.3, # Reduced from 0.4 to 0.3 for snappier feel
        preemptive_generation=True,
        resume_false_interruption=True,
        false_interruption_timeout=1.5, # Increased for maximum stability during hybrid chunking
    )

    usage_collector = metrics.UsageCollector()

    @session.on("metrics_collected")
    def _on_metrics_collected(ev: MetricsCollectedEvent):
        metrics.log_metrics(ev.metrics)
        usage_collector.collect(ev.metrics)

    async def log_usage():
        summary = usage_collector.get_summary()
        logger.info(f"Usage: {summary}")

    ctx.add_shutdown_callback(log_usage)

    # Listen for metadata from frontend
    @ctx.room.on("data_received")
    def on_data_received(data: room_io.DataPacket):
        try:
            import json
            from app.agent import memory
            
            payload = json.loads(data.data.decode())
            if payload.get("type") == "metadata":
                m_id = session_id
                mode = payload.get("mode")
                persona = payload.get("persona")
                prompt = payload.get("prompt")
                
                if mode: memory.session_memory.set_metadata(m_id, "mode_type", mode)
                if persona: memory.session_memory.set_metadata(m_id, "persona_name", persona)
                if prompt: memory.session_memory.set_metadata(m_id, "custom_prompt", prompt)
                
                logger.info(f"[Worker] Metadata updated for {m_id}: mode={mode}, persona={persona}")
        except Exception as e:
            logger.error(f"[Worker] Error parsing data packet: {e}")

    await session.start(
        agent=MyAgent(),
        room=ctx.room,
        room_options=room_io.RoomOptions(
            audio_input=room_io.AudioInputOptions(),
        ),
    )



if __name__ == "__main__":
    cli.run_app(server)